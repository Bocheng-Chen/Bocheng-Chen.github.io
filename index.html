<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Bocheng Chen | University of Mississippi</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.1/normalize.min.css">
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap" rel="stylesheet">
  <style>
    body {
      font-family: 'Inter', sans-serif;
      max-width: 800px;
      margin: auto;
      padding: 20px;
      line-height: 1.6;
    }

    .profile-header {
      display: flex;
      align-items: center;
      gap: 20px;
      justify-content: center; /* 水平居中整个块 */
      margin-bottom: 20px;
    }

    .profile-header img {
      width: 120px;
      border-radius: 10px;
    }

    .profile-info {
      text-align: left; /* 信息内容左对齐 */
    }

    h1 {
      margin: 0;
      font-size: 2em;
    }

    h2 {
      margin-top: 40px;
      font-size: 1.5em;
      padding-bottom: 5px;
    }

    a {
      color: #0073e6;
      text-decoration: none;
    }

    a:hover {
      text-decoration: underline;
    }

    ul {
      padding-left: 20px;
    }

    .contact-links {
      margin-top: 5px;
    }
  </style>
</head>
<body>

  <div class="profile-header">
    <img src="images/selfile-2025.png" alt="Bocheng Chen">
    <div class="profile-info">
      <h1>Bocheng Chen</h1>
      <p><b>Tenure-track Assistant Professor</b><br>
      Computer and Information Science, University of Mississippi</p>
      <p class="contact-links">
        <a href="mailto:bchen5@olemiss.edu">bchen5@olemiss.edu</a> |
        <a href="posts/cv_research_bocheng.pdf">CV</a> |
        <a href="https://scholar.google.com">Google Scholar</a> |
        <a href="https://github.com/Bocheng-Chen">GitHub</a>
      </p>
    </div>
  </div>

  <p>
    My research focuses on <b>computer security</b>, particularly on identifying and mitigating realistic risks in <b>chatbot systems</b> built on large language models (LLMs). 
    My work aims to ensure secure and trustworthy operation of LLM-based chatbots in real-world deployments.
  </p>

  <h2>Research Question</h2>
  <p>
    What is the worst-case behavior when chatbots are widely deployed in real-world settings, and can we design secure chatbot systems given that large language models, due to their probabilistic nature, cannot reliably enforce security policies?
  </p>

  <h2>Research Areas</h2>
  <ul>
    <li>Chatbot system security</li>
    <li>Moral reasoning & alignment in LLMs</li>
    <li>Mitigation of multi-turn and hidden attacks in open-domain chatbots</li>
  </ul>

  <h2>Collaborators</h2>
  <ul>
    <li>Guangliang Liu (Michigan State University)</li>
    <li>Dr. Zoe Xi Chen (Nanyang Technological University) — Pragmatics & Computational Linguistics</li>
  </ul>

  <h2>Selected Papers</h2>

  <h3>Moral reasoning & alignment</h3>
  <ul>
    <li>“Pragmatic Inference for Moral Reasoning Acquisition: Generalization via Distributional Semantics.” — arXiv ’25</li>
    <li>“Diagnosing the Performance Trade-off in Moral Alignment: A Case Study on Gender Stereotypes.” — arXiv ’25</li>
    <li>“No Free Lunch for Defending Against Prefilling Jailbreak Attack by In-Context Learning.” — arXiv ’25</li>
  </ul>

  <h3>Chatbot system security</h3>
  <ul>
    <li>“Understanding Multi-Turn Toxic Behaviors in Open-Domain Chatbots.” — RAID ’23</li>
    <li>“Multi-Turn Hidden Backdoor in Large Language Model-Powered Chatbot Models.” — ASIACCS ’24</li>
    <li>“Jailbreaker in Jail: Moving Target Defense for Large Language Models.” — CCS MTD ’23</li>
  </ul>

</body>
</html>
